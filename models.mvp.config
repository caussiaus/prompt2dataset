# MVP AI Models Configuration
# Minimal set for fast deployment and testing
# Total size: ~12GB

# General LLM (required)
llama3.1

# Vision/OCR (required)
llava

# Embeddings (required for semantic search)
bge-m3

# ─────────────────────────────────────────────────────
# Optional upgrades (uncomment to enable):
# ─────────────────────────────────────────────────────

# Better/faster general LLM
# gemma3          # 2B - faster, less accurate
# mistral-small3.1  # Alternative to llama3.1

# Better vision model
# qwen3-vl        # Better than llava, but larger

# Code/automation tasks
# codellama       # If you need code generation

# ─────────────────────────────────────────────────────
# Notes:
# - This config is optimized for 8GB RAM systems
# - Each model downloads on first startup (5-10 min)
# - You can add more models later without redeployment
# - See full models.config for production options
